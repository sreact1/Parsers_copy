{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# По одной странице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Функция для очистки информации от html кода\n",
    "def html_stripper(text):\n",
    "    return re.sub('<[^<]+?>', '', str(text)) \n",
    "\n",
    "# Функция, которая скачивает одну конкретную страницу\n",
    "# page - номер страницы в списке\n",
    "# Id - номер показателя \n",
    "# date1 - первая дата в табличке\n",
    "# date2 - вторая дата в табличке\n",
    "\n",
    "def getPage(page,ID,date1,date2):\n",
    "    mainpage = 'http://www.banki.ru/banks/ratings/?PAGEN_1='+page+'&search%5Btype%5D=name\\\n",
    "    &sort_param=rating&sort_order=ASC&PROPERTY_ID='+ID+\\\n",
    "    '&REGION_ID=0&date1='+date1+'&date2='+date2+'&IS_SHOW_GROUP=0&IS_SHOW_LIABILITIES=0'\n",
    "    response = requests.get(mainpage)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    return(soup)\n",
    "\n",
    "# Функция, которая скачивает данные с одной страницы в виде матрицы\n",
    "def OnepageDate(soup):\n",
    "    table = soup.findAll(\"tbody\")[2]\n",
    "    banks = table.findAll('a',{ \"class\" : \"widget__link\" })\n",
    "    clean_banks=[re.sub('  |\\n','',html_stripper(item)) for item in banks]\n",
    "    \n",
    "    license = table.findAll('div',{ \"class\" : \"font-size-small color-gray-burn\" })\n",
    "    clean_license = [re.sub('  |\\n','',html_stripper(item)) for item in license]  \n",
    "    \n",
    "    counts = table.findAll('td',{ \"class\" : \"text-align-right\" })\n",
    "    clean_counts = [html_stripper(item) for item in counts]\n",
    "    clean_counts = [re.sub(' |\\n','',item) for item in clean_counts]\n",
    "    n = len(clean_banks)*4\n",
    "    rang = [j for j in range(n) if j%4==0]\n",
    "    bank_indicators = [[clean_counts[i],clean_counts[i+1],clean_counts[i+2],clean_counts[i+3]] for i in rang]\n",
    "    [bank_indicators[i].insert(0,clean_banks[i]) for i in range(len(clean_banks))]\n",
    "    [bank_indicators[i].insert(0,clean_license[i]) for i in range(len(clean_banks))]\n",
    "    \n",
    "    data = bank_indicators\n",
    "    return(data)\n",
    "\n",
    "# Функция, которая выдаёт количество страниц, на которое растягивается таблица с информацией\n",
    "def Number_of_Pages(ID):\n",
    "    mainpage = 'http://www.banki.ru/banks/ratings/?PROPERTY_ID='+ID\n",
    "    response = requests.get(mainpage)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    endpage = math.ceil(int(soup.findAll('span',{'data-bind':'total-items'})[0].text)/50)\n",
    "    return(endpage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Циклы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Проход по конкретной странице и дате вглубину \n",
    "def Page_Deep(data1,data2,ID):\n",
    "    soup = getPage(str(1),ID,data1,data2)\n",
    "    data = OnepageDate(soup)\n",
    "    deep = Number_of_Pages(ID)\n",
    "\n",
    "    for i in range(2,deep+1):\n",
    "        soup = getPage(str(i),ID,data1,data2)\n",
    "        cur_page_data = OnepageDate(soup)\n",
    "        data.extend(cur_page_data)\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Сгенерируем лист из дат, которые необходимо пробежать.\n",
    "# февраль 17 - март 08  (2017-02-01 до  2008-03-01)\n",
    "years = [str(item) for item in range(2008,2018)]\n",
    "months = [str(item) for item in range(1,13)]\n",
    "months2 = [ ]\n",
    "for item in months:\n",
    "    if len(item)==1:\n",
    "        item = '0'+item\n",
    "    months2.append(item)\n",
    "dats = [ ]\n",
    "for item in years:\n",
    "    for jtem in months2:\n",
    "        dats.append(item + '-' + jtem + '-01')\n",
    "dats = dats[2:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Функция, которая выгружает по датам 108 таблиц по конкретному показателю\n",
    "def One_ID_List_Date(ID):\n",
    "    all_data = [ ]\n",
    "    for idate in range(len(dats)-1):\n",
    "        try:\n",
    "            current_data = Page_Deep(dats[(idate+1)],dats[idate],ID)\n",
    "            ddf=pd.DataFrame(current_data)\n",
    "            ddf.columns = ['Лицензия','Банк',dats[(idate+1)],dats[idate],'неважно','неважно']\n",
    "            df = pd.DataFrame()\n",
    "            df['Лицензия']= ddf['Лицензия']\n",
    "            df['Банк']= ddf['Банк']\n",
    "            df[dats[(idate+1)]]=ddf[dats[(idate+1)]]\n",
    "            df[dats[idate]]=ddf[dats[idate]]\n",
    "            all_data.append(df)\n",
    "        except Exception:\n",
    "            all_data.append('Пропуск в данных')\n",
    "            \n",
    "    return(all_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4039.5951693058014 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # время работы кода \n",
    "all_data = One_ID_List_Date('120')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  #время работы кода\n",
    "\n",
    "# Код работал на 30 id около часа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция для создания табличек\n",
    "def Data_frame_uniter(df_vector):\n",
    "    A = df_vector[0]\n",
    "    \n",
    "    a = A.iloc[:,3:4]\n",
    "    A.iloc[:,3:4] = A.iloc[:,2:3]\n",
    "    A.iloc[:,2:3] = a\n",
    "    A.columns = ['Лицензия', 'Банк', list(A.iloc[:,3:4].columns)[0], list(A.iloc[:,2:3].columns)[0]]    \n",
    "    \n",
    "    for item in df_vector[1:]:\n",
    "        dropname = item.columns[3]\n",
    "        new_item = item.drop(dropname,axis=1)\n",
    "        dropname2 = item.columns[1]\n",
    "        newest_item = new_item.drop(dropname2,axis=1)\n",
    "        A = pd.merge(A,newest_item,on='Лицензия',how='outer')        \n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создаём таблицу по конкретному показателю.\n",
    "def data_frame_creator(ID):\n",
    "    all_data = One_ID_List_Date(ID)\n",
    "    new_all_data = [item for item in AAA if len(item) != 16]\n",
    "    A = Data_frame_uniter(new_all_data)\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_frame_creator('25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AAA.to_csv('60.csv',sep=',',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_list = ['10','30','25','20','40','50','60','500','1000','1100','1200','1300','1400','1500','1550',\\\n",
    "           '1600','1700','1800','200','260','300','360','120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_list = ID_list[3:5]\n",
    "ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Цикл для выгрузки информации по каждому ID:\n",
    "for ID in ID_list:\n",
    "    data_id = data_frame_creator(ID)\n",
    "    data_id.to_csv(ID + '.csv',sep=',',header=True,index=False)\n",
    "    #сохраним в файл с помощью пандас!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопоставление критериев и их ID:\n",
    "\n",
    "- Активы нетто: na     10\n",
    "- Чистая прибыль ni    30\n",
    "- Капитал (по форме 123) c_123     25\n",
    "- Капитал (по форме 134) c_134     20\n",
    "- Кредитный портфель cp   40\n",
    "- Просроченная задолженность в кредитном портфеле LLPGL   50\n",
    "- Вклады физических лиц dep_f      60\n",
    "- Средства предприятий и организаций dep_b   500\n",
    "- Рентабельность активов-нетто ROA    1000\n",
    "- Рентабельность капитала ROE         1100 \n",
    "- Уровень просроченной задолженности по кредитному портфелю LLP   1200\n",
    "- Уровень резервирования по кредитному портфелю lR    1300\n",
    "- Уровень обеспечения кредитного портфеля залогом имущества LCP      1400\n",
    "- Валютный оборот к активам-нетто fr_na            1500\n",
    "- Оборот по валютным операциям в тыс. рублей fr    1550\n",
    "- Н1 H1    1600\n",
    "- Н2 H2    1700\n",
    "- Н3 H3    1800\n",
    "- Кредиты физическим лицам c_f    200\n",
    "- Просроченная задолженность по кредитам физическим лицам LLP_c_f   260\n",
    "- Кредиты предприятиям и организациям c_b   300\n",
    "- Просроченная задолженность по кредитам предприятиям и организациям LLP_c_b   360\n",
    "- Выданные МБК ibl   120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Доделать: \n",
    "# 1) 20 + датафреймов по каждому id (сохранить)\n",
    "# 2) Составить список всех банков, составить список плохих банков (второй парсер)\n",
    "# 3) Унифицировать все датафреймы, заменить всяике н.д. на NA. Проверить коректность. \n",
    "# 3.1) Составить таблицу для зависимой переменной из нулей и единиц \n",
    "# 4) Перевести в формат панелей    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#создание DataFrame с помощью чтения данных из файла\n",
    "frame = pd.read_csv('10.csv', header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Информация о банках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Bank_parser(number):\n",
    "    bad_page = 'http://www.banki.ru/banks/memory/?by=PROPERTY_date&order=desc&PAGEN_1='+str(number)\n",
    "    response = requests.get(bad_page)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    return(soup)\n",
    "\n",
    "\n",
    "def get_cause(url):\n",
    "    page = mainpage + url\n",
    "    response = requests.get(page)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    cause = soup.findAll('dd',{'class':\"margin-bottom-zero\"})\n",
    "    return(cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bankrot = {'Банк':[], 'хреф': [], 'статус': [], 'ликвдата': [], 'причина': []}\n",
    "for i in range(1,52):\n",
    "    bank_page = Bank_parser(i)\n",
    "    curvec = bank_page.findAll(\"tbody\")[2].findAll('td')\n",
    "    \n",
    "    bank = [html_stripper(curvec[1+i*6].findAll('a')[0]) for i in range(int(len(curvec)/6))]\n",
    "    href = [re.split('=\"|\">',str(curvec[1+i*6].findAll('a')[0]))[1] for i in range(int(len(curvec)/6))]\n",
    "    status = [html_stripper(curvec[3+i*6]) for i in range(int(len(curvec)/6))]\n",
    "    likvid_data = [html_stripper(curvec[4+i*6]) for i in range(int(len(curvec)/6))]\n",
    "\n",
    "    mainpage = 'http://www.banki.ru'\n",
    "    cause = [get_cause(item) for item in href]  # убрал [0].text из-за ошибки\n",
    "    bankrot['Банк'].extend(bank)\n",
    "    bankrot['хреф'].extend(href)\n",
    "    bankrot['статус'].extend(status)\n",
    "    bankrot['ликвдата'].extend(likvid_data)\n",
    "    bankrot['причина'].extend(cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bankrot['Банк'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closed_banks = pd.DataFrame(bankrot)\n",
    "closed_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_povod = [ ] \n",
    "for item in closed_banks['причина']:\n",
    "    if item == []:\n",
    "        new_povod.append('Причина не указана')\n",
    "    else:\n",
    "        new_povod.append(item[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "closed_banks['Причина'] = new_povod  # новая причина с большой буквы П, старая с маленькой!\n",
    "closed_banks.drop('причина',axis=1,inplace=True) # дропаем старую причину!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Списики банков!\n",
    "likvid_banks = closed_banks[closed_banks['статус']=='ликв.']['Банк']\n",
    "otozv_banks = closed_banks[closed_banks['статус']=='отозв.']['Банк']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(likvid_banks) + len(otozv_banks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Причины по ликвидированным банкам: \n",
    "likvid_data = closed_banks[closed_banks['статус']=='ликв.']\n",
    "otozv_data = closed_banks[closed_banks['статус']=='отозв.']\n",
    "\n",
    "likvid_data.to_csv('likvid_data.csv',sep='\\t',header=True,index=False)\n",
    "otozv_data.to_csv('otozv_data.csv',sep='\\t',header=True,index=False)\n",
    "\n",
    "likvid_banks.to_csv('likvid_banks.csv',sep='\\t',header=True,index=False)\n",
    "otozv_banks.to_csv('otozv_banks.csv',sep='\\t',header=True,index=False)\n",
    "# closed_banks = pd.read_csv('bankrot.csv',sep='\\n',header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge multiple dataframes\n",
    "# merge(A, B, left_on='lkey', right_on='rkey', how='outer')\n",
    "\n",
    "df1 = pd.DataFrame(np.array([\n",
    "    ['a', 5, 9],\n",
    "    ['b', 4, 61],\n",
    "    ['c', 24, 9]]),\n",
    "    columns=['name', 'attr11', 'attr12'])\n",
    "df2 = pd.DataFrame(np.array([\n",
    "    ['d', 5, 19],\n",
    "    ['b', 14, 16],\n",
    "    ['e', 4, 9]]),\n",
    "    columns=['name', 'attr21', 'attr22'])\n",
    "df3 = pd.DataFrame(np.array([\n",
    "    ['a', 15, 49],\n",
    "    ['b', 4, 36],\n",
    "    ['e', 14, 9]]),\n",
    "    columns=['name', 'attr31', 'attr32'])\n",
    "\n",
    "pd.merge(pd.merge(df1,df2,on='name',how='outer'),df3,on='name',how='outer')\n",
    "\n",
    "A = df1.merge(df2,on='name',how='outer').merge(df3,on='name',how='outer')\n",
    "A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
